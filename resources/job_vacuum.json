{
  "name": "job_vacuum",
  "email_notifications": {
    "no_alert_for_skipped_runs": false
  },
  "webhook_notifications": {},
  "timeout_seconds": 0,
  "max_concurrent_runs": 1,
  "tasks": [
    {
      "task_key": "job_vacum",
      "run_if": "ALL_SUCCESS",
      "spark_python_task": {
        "python_file": "source/job_vacuum/run_job.py",
        "source": "GIT"
      },
      "job_cluster_key": "Job_cluster",
      "timeout_seconds": 0,
      "email_notifications": {},
      "notification_settings": {
        "no_alert_for_skipped_runs": false,
        "no_alert_for_canceled_runs": false,
        "alert_on_last_attempt": false
      },
      "webhook_notifications": {}
    }
  ],
  "job_clusters": [
    {
      "job_cluster_key": "Job_cluster",
      "new_cluster": {
        "cluster_name": "",
        "spark_version": "13.3.x-scala2.12",
        "spark_conf": {
          "spark.databricks.service.server.enabled": "true",
          "spark.databricks.hive.metastore.glueCatalog.enabled": "true",
          "spark.hadoop.fs.s3a.acl.default": "BucketOwnerFullControl",
          "spark.sql.sources.partitionOverwriteMode": "dynamic",
          "spark.databricks.service.port": "15001"
        },
        "aws_attributes": {
          "instance_profile_arn": "arn:aws:iam::463684499885:instance-profile/DatabricksGlueHML"
        },
        "spark_env_vars": {
          "PYSPARK_PYTHON": "/databricks/python3/bin/python3"
        },
        "instance_pool_id": "0909-182431-gnome115-pool-nwnb239s",
        "driver_instance_pool_id": "0909-175538-need114-pool-54ru5kw0",
        "data_security_mode": "SINGLE_USER",
        "runtime_engine": "STANDARD",
        "num_workers": 1
      }
    }
  ],
  "git_source": {
    "git_url": "https://github.com/douglasjr1985/databricks_workflow",
    "git_provider": "gitHub",
    "git_branch": "main"
  },
  "run_as": {
    "user_name": "douglas.dos.ext@dock.tech"
  }
}
